{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        print(f'The folder {folder_path} does not exist.')\n",
    "delete_all_in_folder('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value: int):\n",
    "    \"\"\"\n",
    "    Set the seed for reproducibility in Python, NumPy, and PyTorch.\n",
    "    Args:\n",
    "    - seed_value (int): The seed value to use for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_value = 42\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100ColorizationDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        for subdir in sorted(os.listdir(folder)):\n",
    "            subdir_path = os.path.join(folder, subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                for img_name in os.listdir(subdir_path):\n",
    "                    img_path = os.path.join(subdir_path, img_name)\n",
    "                    if img_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.samples.append(img_path)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        gray_image = transforms.functional.rgb_to_grayscale(image)\n",
    "        gray_image = gray_image.repeat(3, 1, 1)\n",
    "        return gray_image, image\n",
    "class ColorizationResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationResNet, self).__init__()\n",
    "        resnet = models.resnet50(weights=False)\n",
    "        self.encoder_layers = list(resnet.children())[:-2]\n",
    "        self.encoder1 = nn.Sequential(*self.encoder_layers[:4])\n",
    "        self.encoder2 = self.encoder_layers[4]\n",
    "        self.encoder3 = self.encoder_layers[5]\n",
    "        self.encoder4 = self.encoder_layers[6]\n",
    "        self.encoder5 = self.encoder_layers[7]\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2048, 1024, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024 + 1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512 + 512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256 + 256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128 + 64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "            nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "        dec5 = self.decoder5(enc5)\n",
    "        dec5 = nn.functional.interpolate(dec5, size=enc4.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec4 = self.decoder4(torch.cat([dec5, enc4], dim=1))\n",
    "        dec4 = nn.functional.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec3 = self.decoder3(torch.cat([dec4, enc3], dim=1))\n",
    "        dec3 = nn.functional.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec2 = self.decoder2(torch.cat([dec3, enc2], dim=1))\n",
    "        dec2 = nn.functional.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec1 = self.decoder1(torch.cat([dec2, enc1], dim=1))\n",
    "        output = self.final_layer(dec1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image, mean=None, std=None):\n",
    "    return torch.clamp(image, 0, 1)\n",
    "def plot_examples(dataset, num_examples=10):\n",
    "    fig, axes = plt.subplots(num_examples, 2, figsize=(10, 5 * num_examples))\n",
    "    fig.suptitle('Original Color Image and Grayscale Image')\n",
    "    for i in range(num_examples):\n",
    "        idx = random.randint(0, len(dataset) - 1)\n",
    "        gray_image, color_image = dataset[idx]\n",
    "        color_image_np = color_image.permute(1, 2, 0).numpy()\n",
    "        gray_image_np = gray_image.permute(1, 2, 0).numpy()\n",
    "        axes[i, 0].imshow(color_image_np)\n",
    "        axes[i, 0].set_title('Original Color Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(gray_image_np[..., 0], cmap='gray')\n",
    "        axes[i, 1].set_title('Grayscale Image')\n",
    "        axes[i, 1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_predictions(model, dataset, device, num_examples=5):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_examples, 3, figsize=(15, 5 * num_examples))\n",
    "    fig.suptitle('Original, Grayscale, and Predicted Images')\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_examples):\n",
    "            idx = random.randint(0, len(dataset) - 1)\n",
    "            gray_image, color_image = dataset[idx]\n",
    "            gray_image = gray_image.unsqueeze(0).to(device)\n",
    "            predicted_image = model(gray_image)\n",
    "            predicted_image = predicted_image.squeeze(0).cpu()\n",
    "            color_image_np = color_image.permute(1, 2, 0).numpy()\n",
    "            predicted_image_np = predicted_image.permute(1, 2, 0).numpy()\n",
    "            gray_image_np = gray_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "            axes[i, 0].imshow(color_image_np)\n",
    "            axes[i, 0].set_title('Original Color Image')\n",
    "            axes[i, 0].axis('off')\n",
    "            axes[i, 1].imshow(gray_image_np[..., 0], cmap='gray')\n",
    "            axes[i, 1].set_title('Grayscale Image')\n",
    "            axes[i, 1].axis('off')\n",
    "            axes[i, 2].imshow(predicted_image_np)\n",
    "            axes[i, 2].set_title('Predicted Color Image')\n",
    "            axes[i, 2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(model, dataset, device, epoch, num_examples=5, save_dir='/kaggle/working'):\n",
    "    model.eval()\n",
    "    epoch_dir = os.path.join(save_dir, f'epoch{epoch}')\n",
    "    os.makedirs(epoch_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_examples):\n",
    "            idx = random.randint(0, len(dataset) - 1)\n",
    "            gray_image, color_image = dataset[idx]\n",
    "            gray_image = gray_image.unsqueeze(0).to(device)\n",
    "            predicted_image = model(gray_image)\n",
    "            predicted_image = predicted_image.squeeze(0).cpu()\n",
    "            gray_image_np = gray_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "            predicted_image_np = predicted_image.permute(1, 2, 0).numpy()\n",
    "            color_image_np = color_image.permute(1, 2, 0).numpy()\n",
    "            gray_image_path = os.path.join(epoch_dir, f'example_{i+1}_gray.png')\n",
    "            predicted_image_path = os.path.join(epoch_dir, f'example_{i+1}_predicted.png')\n",
    "            original_image_path = os.path.join(epoch_dir, f'example_{i+1}_original.png')\n",
    "            plt.imsave(gray_image_path, gray_image_np[..., 0], cmap='gray')\n",
    "            plt.imsave(predicted_image_path, predicted_image_np)\n",
    "            plt.imsave(original_image_path, color_image_np)\n",
    "    print(f\"Saved predictions for epoch {epoch} in {epoch_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "        for gray_images, color_images in progress_bar:\n",
    "            gray_images, color_images = gray_images.to(device), color_images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(gray_images)\n",
    "            loss = criterion(outputs, color_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * gray_images.size(0)\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        tqdm.write(f'Training Loss: {epoch_loss:.4f}')\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for gray_images, color_images in progress_bar:\n",
    "                gray_images, color_images = gray_images.to(device), color_images.to(device)\n",
    "                outputs = model(gray_images)\n",
    "                loss = criterion(outputs, color_images)\n",
    "                running_val_loss += loss.item() * gray_images.size(0)\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        tqdm.write(f'Validation Loss: {epoch_val_loss:.5f}')\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), 'bestmodel.pth')\n",
    "            tqdm.write(f\"Best model saved with validation loss: {best_val_loss:.5f}\")\n",
    "        plot_predictions(model, val_set, device, num_examples=5)\n",
    "        save_predictions(model, val_set, device, epoch, num_examples=5, save_dir='/kaggle/working')\n",
    "def test(model, test_loader, criterion):\n",
    "    model.load_state_dict(torch.load('bestmodel.pth'))\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    progress_bar = tqdm(test_loader, desc=\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        for gray_images, color_images in progress_bar:\n",
    "            gray_images, color_images = gray_images.to(device), color_images.to(device)\n",
    "            outputs = model(gray_images)\n",
    "            loss = criterion(outputs, color_images)\n",
    "            running_test_loss += loss.item() * gray_images.size(0)\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "    test_loss = running_test_loss / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    Normalize(mean,std)\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = CIFAR100ColorizationDataset(folder='/kaggle/input/cifar100/cifar100/train', transform=transform)\n",
    "test_dataset = CIFAR100ColorizationDataset(folder='/kaggle/input/cifar100/cifar100/test', transform=transform)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(len(train_dataset))), test_size=0.20, stratify=[train_dataset.samples[i].split('/')[-2] for i in range(len(train_dataset))]\n",
    ")\n",
    "train_set = Subset(train_dataset, train_idx)\n",
    "val_set = Subset(train_dataset, val_idx)\n",
    "print(f'Training set size: {len(train_set)}')\n",
    "print(f'Validation set size: {len(val_set)}')\n",
    "print(f'Test set size: {len(test_dataset)}')\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "model = ColorizationResNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(val_set, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5333955,
     "sourceId": 8914197,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5521309,
     "sourceId": 9141698,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
