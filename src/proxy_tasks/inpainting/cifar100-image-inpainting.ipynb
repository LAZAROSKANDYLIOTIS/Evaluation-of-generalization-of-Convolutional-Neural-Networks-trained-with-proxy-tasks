{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_in_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        print(f'The folder {folder_path} does not exist.')\n",
    "delete_all_in_folder('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value: int):\n",
    "    \"\"\"\n",
    "    Set the seed for reproducibility in Python, NumPy, and PyTorch.\n",
    "    Args:\n",
    "    - seed_value (int): The seed value to use for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_value = 42\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100InpaintingDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append(os.path.join(root, file))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        mask = self.generate_random_mask(image.size(1), image.size(2))\n",
    "        masked_image = image * (1 - mask)\n",
    "        return masked_image, mask, image\n",
    "    def generate_random_mask(self, height, width):\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for _ in range(5):\n",
    "            x1, y1 = random.randint(0, width-1), random.randint(0, height-1)\n",
    "            x2, y2 = random.randint(0, width-1), random.randint(0, height-1)\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), 1, thickness=random.randint(1, 5))\n",
    "        for _ in range(5):\n",
    "            x, y = random.randint(0, width-1), random.randint(0, height-1)\n",
    "            radius = random.randint(5, 20)\n",
    "            cv2.circle(mask, (x, y), radius, 1, -1)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "        return mask\n",
    "    def get_sample(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        mask = self.generate_random_mask(image.size(1), image.size(2))\n",
    "        masked_image = image * (1 - mask)\n",
    "        return masked_image, mask, image\n",
    "class EnhancedInpaintingResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedInpaintingResNet, self).__init__()\n",
    "        resnet = models.resnet50(weights=False)\n",
    "        self.encoder_layers = list(resnet.children())[:-2]\n",
    "        self.encoder1 = nn.Sequential(*self.encoder_layers[:4])\n",
    "        self.encoder2 = self.encoder_layers[4]\n",
    "        self.encoder3 = self.encoder_layers[5]\n",
    "        self.encoder4 = self.encoder_layers[6]\n",
    "        self.encoder5 = self.encoder_layers[7]\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2048, 1024, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024 + 1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512 + 512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256 + 256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128 + 64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "            nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "        dec5 = self.decoder5(enc5)\n",
    "        dec5 = nn.functional.interpolate(dec5, size=enc4.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec4 = self.decoder4(torch.cat([dec5, enc4], dim=1))\n",
    "        dec4 = nn.functional.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec3 = self.decoder3(torch.cat([dec4, enc3], dim=1))\n",
    "        dec3 = nn.functional.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec2 = self.decoder2(torch.cat([dec3, enc2], dim=1))\n",
    "        dec2 = nn.functional.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec1 = self.decoder1(torch.cat([dec2, enc1], dim=1))\n",
    "        output = self.final_layer(dec1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_plot_samples(dataset, num_samples=10):\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    sampled_indices = random.sample(range(len(dataset)), num_samples)\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        masked_image, mask, original_image = dataset.get_sample(idx)\n",
    "        original_image_np = original_image.permute(1, 2, 0).numpy()\n",
    "        masked_image_np = masked_image.permute(1, 2, 0).numpy()\n",
    "        mask_np = mask.squeeze(0).numpy()\n",
    "        masked_image_np[mask_np == 1] = 0\n",
    "        axs[i, 0].imshow(original_image_np)\n",
    "        axs[i, 0].set_title('Original Image')\n",
    "        axs[i, 0].axis('off')\n",
    "        axs[i, 1].imshow(mask_np, cmap='gray')\n",
    "        axs[i, 1].set_title('Mask')\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 2].imshow(masked_image_np)\n",
    "        axs[i, 2].set_title('Masked Image')\n",
    "        axs[i, 2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(model, dataset, device, epoch, num_examples=5, save_dir='/kaggle/working'):\n",
    "    model.eval()\n",
    "    epoch_dir = os.path.join(save_dir, f'epoch{epoch}')\n",
    "    os.makedirs(epoch_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_examples):\n",
    "            idx = random.randint(0, len(dataset) - 1)\n",
    "            masked_image, mask, original_image = dataset.get_sample(idx)\n",
    "            masked_image = masked_image.unsqueeze(0).to(device)\n",
    "            predicted_image = model(masked_image)\n",
    "            predicted_image = predicted_image.squeeze(0).cpu()\n",
    "            mask = mask.expand_as(predicted_image)\n",
    "            inpainted_image = original_image.clone()\n",
    "            inpainted_image[mask == 1] = predicted_image[mask == 1]\n",
    "            original_image_np = original_image.permute(1, 2, 0).numpy()\n",
    "            masked_image_np = masked_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "            inpainted_image_np = inpainted_image.permute(1, 2, 0).numpy()\n",
    "            original_image_path = os.path.join(epoch_dir, f'example_{i+1}_original.png')\n",
    "            masked_image_path = os.path.join(epoch_dir, f'example_{i+1}_masked.png')\n",
    "            inpainted_image_path = os.path.join(epoch_dir, f'example_{i+1}_predicted.png')\n",
    "            plt.imsave(original_image_path, original_image_np)\n",
    "            plt.imsave(masked_image_path, masked_image_np)\n",
    "            plt.imsave(inpainted_image_path, inpainted_image_np)\n",
    "    print(f\"Saved predictions for epoch {epoch} in {epoch_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, dataset, criterion, optimizer, num_epochs=50, device='cuda'):\n",
    "    best_val_loss = float('inf')\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for masked_img, mask, original_img in tqdm(train_loader, desc=f'Training Epoch {epoch+1}/{num_epochs}'):\n",
    "            masked_img, mask, original_img = masked_img.to(device), mask.to(device), original_img.to(device)\n",
    "            outputs = model(masked_img)\n",
    "            mask = mask.expand_as(outputs)\n",
    "            inpainted_img = masked_img.clone()\n",
    "            inpainted_img[mask == 1] = outputs[mask == 1]\n",
    "            loss = criterion(outputs * mask, original_img * mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.5f}')\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for masked_img, mask, original_img in tqdm(val_loader, desc='Validation'):\n",
    "                masked_img, mask, original_img = masked_img.to(device), mask.to(device), original_img.to(device)\n",
    "                outputs = model(masked_img)\n",
    "                mask = mask.expand_as(outputs)\n",
    "                inpainted_img = masked_img.clone()\n",
    "                inpainted_img[mask == 1] = outputs[mask == 1]\n",
    "                loss = criterion(outputs * mask, original_img * mask)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Validation Loss: {avg_val_loss:.5f}')\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'bestmodel.pth')\n",
    "            print(f\"Saved new best model with validation loss: {best_val_loss:.5f}\")\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            save_predictions(model, dataset, device, epoch + 1, num_examples=5)\n",
    "def test(model, test_loader, criterion, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for masked_img, mask, original_img in tqdm(test_loader, desc='Testing'):\n",
    "            masked_img, mask, original_img = masked_img.to(device), mask.to(device), original_img.to(device)\n",
    "            outputs = model(masked_img)\n",
    "            mask = mask.expand_as(outputs)\n",
    "            inpainted_img = original_img.clone()\n",
    "            inpainted_img[mask == 1] = outputs[mask == 1]\n",
    "            loss = criterion(outputs * mask, original_img * mask)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f'Test Loss: {avg_test_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = CIFAR100InpaintingDataset(folder='/kaggle/input/cifar100/cifar100/train', transform=transform)\n",
    "test_dataset = CIFAR100InpaintingDataset(folder='/kaggle/input/cifar100/cifar100/test', transform=transform)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(len(train_dataset))), test_size=0.20, stratify=[train_dataset.samples[i].split('/')[-2] for i in range(len(train_dataset))]\n",
    ")\n",
    "train_set = Subset(train_dataset, train_idx)\n",
    "val_set = Subset(train_dataset, val_idx)\n",
    "print(f'Training set size: {len(train_set)}')\n",
    "print(f'Validation set size: {len(val_set)}')\n",
    "print(f'Test set size: {len(test_dataset)}')\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "model = EnhancedInpaintingResNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_plot_samples(train_dataset, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(model, train_loader, val_loader, train_dataset, criterion, optimizer, num_epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('bestmodel.pth'))\n",
    "test(model, test_loader, criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5333955,
     "sourceId": 8914197,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
